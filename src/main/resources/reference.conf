hyperstorage: {
  max-workers:   1024
  shutdown-timeout:         30s
  shard-sync-timeout:       1s
  background-task-timeout:  2min      // minutes to wait for background task completion
  request-timeout:          15s
  fail-timeout:             3min      // If older then transaction considered failed and we try to recover it with hot-recovery, should be less than `hot-recovery`
  hot-recovery:             30min     // tried to recovery in hot-mode (more often), should be less than `oldest-recovery`
  hot-recovery-retry:       15s       // when retry after recovery fail
  stale-recovery:           1d        // If there is no checkpoint for the partition then we start recovering from oldest. stale-recovery configuration
  stale-recovery-retry:     3min      // when retry after recovery fail

  actor-system: {
    actor-system-name: hyperstorage
    log-messages: true
    deque-dispatcher: {
      executor = "thread-pool-executor"
      type = Dispatcher
    }
    akka {
      loggers = ["akka.event.slf4j.Slf4jLogger"]
      loglevel = "INFO"
      actor {
        provider = "akka.cluster.ClusterActorRefProvider"
      }
      remote {
        log-remote-lifecycle-events = off
        netty.tcp {
          hostname = "127.0.0.1"
          port = 2550
        }
      }

      cluster {
        seed-nodes = [
          "akka.tcp://hyperstorage@127.0.0.1:2550"
        ]
        auto-down-unreachable-after = off
        roles = ["hyperstorage"]
      }

      contrib.cluster.pub-sub {
        name = distributedPubSubMediator
        role = ""
        gossip-interval = 1s
        removed-time-to-live = 120s
      }
    }
  }

  cassandra: {
    keyspace: "hyperstorage"
    hosts: [127.0.0.1]
    datacenter: ""
    connect-timeout: 10000
    read-timeout: 30000
  }

  zmq-cluster-manager: {
    node: {
      advertised-address: 127.0.0.1
      advertised-port: 2560
    }
    consul: {
      address: "localhost:8500"
      service-registrator: {
        node-id: ${hyperstorage.zmq-cluster-manager.node.advertised-address}-${hyperstorage.zmq-cluster-manager.node.advertised-port}
        address: ${hyperstorage.zmq-cluster-manager.node.advertised-address}
        port: ${hyperstorage.zmq-cluster-manager.node.advertised-port}
        service-map: []
        update-interval: 3s
      }
      service-resolver: {
        service-map: []
        cache-period: 60s
        consistency-mode: CONSISTENT
        watch-time: 10s
      }
    }

    hyperbus: {
      read-messages-log-level = TRACE
      write-messages-log-level = TRACE
      transports: {
        zmq-server: {
          class-name: com.hypertino.hyperbus.transport.ZMQServer
          port: ${hyperstorage.zmq-cluster-manager.node.advertised-port}
          interface: "*"
          zmq-io-threads: 1
          max-sockets: 55000
          response-timeout: 30s
        }

        zmq-client: {
          class-name: com.hypertino.hyperbus.transport.ZMQClient
          default-port: ${hyperstorage.zmq-cluster-manager.node.advertised-port}
          zmq-io-threads: 1
          ask-timeout: 35s
          keep-alive-timeout: 60s
          max-sockets: 55000
          max-output-queue-size: 16384
        }
      }

      client-routes: [
        {
          transport: zmq-client
        }
      ]

      server-routes: [
        {
          transport: zmq-server
          registrator: hyperstorage-cluster-registrator
        }
      ]
    }
  }
}
